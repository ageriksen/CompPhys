\documentclass[10pt, twocolumn]{article}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{dcolumn}
\usepackage{bm}
\usepackage[colorlinks=true,urlcolor=blue,citecolor=blue]{hyperref}
\usepackage{color}
\usepackage[numbers]{natbib}
\usepackage{dsfont}

%\begin{figure}[hbtp]
%\includegraphics[scale=0.4]{filename.extension}
%\caption{description of figure} 
%\label{honestly, I don't know what label does}
%\end{figure}

\begin{document}
\title{Project 1}
\author{Anders Eriksen}

\maketitle

\begin{abstract}
%"Accurate and informative" (5pts)

\end{abstract}

\section{Introduction}
%"status of problem, major objectives" (10pts)

\section{Theory, algorithms and methods}
%"Discussion of methods used and their basis/suitability" (20pts)
We examine  2-point boundary value systems.this leads to discrete energies, in effect eigenvalues. 
Our initial methods model a buckling beam between 2 fastened points. This has analytical solutions 
and is therefore a good start to test our methods. Our starting point is\cite{project2pdf}:
\[
\gamma \frac{d^2 u(x)}{dx^2} = -F u(x),
\]
with $\gamma$ as a system constant, the force F working on the beam at it's endpoint, a distance L 
from the origin, and $u(x)$ is the displacement of the beam in the y direction. We impose the 
Dirichlet boundary conditions and set the exremes $u(0) = u(L) = 0$. Naturally, our position 
$x \in \{ 0, L \}$. As an example to explore solutions to boundary value problems, we naturally 
treat the values $\gamma$, $F$ and $L$ as known quantities. \\

Our first step in our towards a solution, is to scale the function. And the first toe of this 
footstep is to introduce a dimensionless variable $ \rho = \frac{r}{L} $, which necessarily follows 
$\rho \in [0,1]$. Next comes introducing $\lambda = \frac{FL^2}{R}$. This leads to the eigenvalue 
problem
\[
\frac{d^2u(\rho )}{d\rho^2} = -\lambda u(\rho)
\]

This can be approximated through a Taylor expansion and inserting the '-' sign from in front of our 
$\lambda$:
\[
u'' = \frac{-u(\rho + h) - u(\rho - h) + 2u(\rho)}{h^2} + {O}(h^2)
\]
With h as our stepsize.\

intending to walk from $\rho = 0$ to $1$ in $N$ steps, we naturally derive our steplength as 
$h = \frac{\rho_N - \rho_0}{N} = \frac{1}{N}$. Letting $i \in \{ 1, 2, \ldots, N\}$ for 
\[\rho_i = \rho_0 + ih = ih\] and
\[ -\frac{u_{i+1} + u_{i-1} - 2u_{i}}{h^2} = \lambda u_i\]
This relationship can be conveniently converted into a matrix format, which is handy in linalg 
operations to extract sollutions. 
\begin{equation}
    \begin{bmatrix} d& a & 0   & 0    & \cdots  &0     & 0 \\
                                a & d & a & 0    & \cdots  &0     &0 \\
                                0   & a & d & a  &0       &\cdots & 0\\
                                \dots  & \cdots & \cdots & \cdots  &\cdots      &\cdots & \cdots\\
                                0   & \cdots & \cdots & \cdots  &a  &d & a\\
                                0   & \cdots & \cdots & \cdots  &\cdots       &a & d\end{bmatrix} 
                                 \begin{bmatrix} u_1 \\ u_2 \\ u_3 \\ \dots \\ u_{N-2} \\ u_{N-1}\end{bmatrix} 
                                     = \lambda \begin{bmatrix} u_1 \\ u_2 \\ u_3 \\ \dots \\ u_{N-2} \\ u_{N-1}\end{bmatrix} . 
\label{eq:matrixse} 
\end{equation}
Where our tridiagonal matrix has elements "d" along the diagonal, naturally, and a along the 
off diagonals. We set $d = \frac{2}{h^2}$ and $a = -\frac{1}{h^2}$. We also keep the $0^{th}$ 
and $N^{th}$ elements out of the matrix, in part as our endpoints are known, but also because 
they are set. They will never change, because they are fastened. In my code, I refer to these 
elements as "diagonal" and "semidiagonal" to clarify. 

This setup has analytical eigenvalues. They follow the form
\[ \lambda_j = d + 2acos(\frac{j\pi}{N+1}) \;\; j = 1, 2, \cdots, N-1 \]\\


There is a solution to these matrices, where a matrix A can be transformed through a similarity 
transformation so that $\hat{S}^T \hat{A} \hat{S} = \hat{B}$ where $\hat{B}$ is a diagonal matrix 
with eigenvalues $\lambda$ along the diagonal. A similarity transformation also requires that 
$\hat{S}^T\hat{S} = \mathds{1}$, or $\hat{S}$ is unitary. 

first off, we must show that the unitatry transformations retain orthogonality. 

We start off with an assumed orthonormal set $v_i$, so
\[
\vec{v_i}^T \cdot \vec{v_j} = \delta_{ij}
\]
A unitary transformation means an operator $U$ working on $v_i$.
With a $\vec{w_{i}} = \hat{U}\vec{v_{i}}$, for which 
$\vec{w_{i}}^T = \vec{v_{i}}^T\hat{U}^T$ we have 
\[
    \vec{w_{i}}^T\vec{w_{j}} = \vec{v_i} \hat{U}^T \hat{U} \vec{v_j} 
\]
\[
    \hat{U}^T \hat{U} = \mathds{1} 
\]
\[
    \vec{w_i}^T\vec{w_j} = \vec{v_i}^T\vec{v_j} = \delta_{i,j}
\]\\

In other words, as long as our transformations are unitary, the vectors retain 
orthogonality. They are still orthogonal, but not the same. \\

Now, $1$ similarity transformation is not necessarily enough, but several repeated such can 
bring us where we want to go. This is where Jacobis's method comes into play. The matrix we use is
an identity matrix, where $4$ elements have been changed. $a_{ll} = a_{kk} = \cos(\theta)$, 
$a_{kl} = -a_{lk} = -\sin(\theta)$, $j \neq k$. One similarity transformation leads to a change in 
the following elements: 
\[ b_{ii} = a_{ii} \; \; i \neq k, i \neq l \]
\[ b_{ik} = a_{ik}\cos(\theta) - a_{il}\sin(\theta) \; \; i \neq k, i \neq l \]
\[ b_{il} = a_{il}\cos(\theta) + a_{ik}\sin(\theta) \; \; i \neq k, i \neq l \]
\[ b_{kk} = a_{kk}\cos^2(\theta) - 2a_{kl}\cos(\theta)\sin(\theta) + a_{ll}\sin^2(\theta) \]
\[ b_{ll} = a_{ll}\cos^2(\theta) + 2a_{kl}\cos(\theta)\sin(\theta) + a_{kk}\sin^2(\theta) \]
\[ b_{kl} = (a_{kk} - a_{ll})\cos(\theta)\sin(\theta) + a_{kl}(\cos^2(\theta) - \sin^2(\theta)) \]

For each such rotation, we choose our angles so that $a_{kl} = 0$. This is repeated until each non-diagonal
matrix element becomes 0, or at least within a tolerance of 0. Note that the elements $b_{il} \& b_{ik}$
change with each rotation as well. This means that for each rotation, we isturb slightly a few other 
elements. When transforming a matrix as such, with each rotation we find the largest element and designate
this as our $a_{kl}$. Eventually, As the elements perturbed by each transformation are scaled by numbers less
than 1, we must eventually reach a point where the only remainder is the diagonlal. At which point, we have
our $\hat{B}$ with eigenvalues. With each step, the sum of all off-diagonal elements in $\hat{B}$ be given 
as $off(\hat{B})^2 = off(\hat{A})^2 - 2a_{kl}$ and we see that per iteration, the sum of off daigonal elements 
decreases. 

If we want $b_{kl}$ to be null, we can rearrange the expression into one for $\cot(2x)$\cite{rottmann2006matematisk}, 
which gives us $\cot(2\theta) = \tau = \frac{a_{ll} - a_{kl}}{2a_{kl}}$. We also make similar approximations to 
$\tan$, $\cos$ and $\sin$, as $t, c, s$ respectively. with $t = \frac{s}{c} $. The expression for $\cot(2\theta)$
can be rewritten as $cot(2\theta) = \frac{1}{2}(\cot(\theta) - \tan(\theta))$ which can be solved for $t$ as 
\[ t^2 + 2\tau t - 1 = 0 \]
\[ t = - \tau \pm \sqrt{1 + \tau^2} \]
And from this, we get $c = \frac{1}{\sqrt{1 + t^2}} \& s = tc$

Our algorithm then must choose the largest nondiagonal matrix element and set this as our $a_kl$ before rotating the 
matrix so that this element is 0, finding here the values for $s$ and $c$. After inserting the values into the 
relevant elements, we go back to the top. This repeats as long as the largest offdiagonal is greater than a tolerance 
for 0.

\section{Code, implementation and tests}
%"Readability of code, implementation, testing and discussion of benchmarks" (20)

\section{Analysis}
%"Analysis of the results and effectiveness of selection and presentation. Results well 
% understood and discussed" (20pts)


\section{conclusions}
%"conclusions, Discussion and critical comments on what was learned about the method used 
% and results obtained. Possible directions for future improvement?" (10pts)


\bibliography{mybib}
\bibliographystyle{plain}
\end{document}
%%%%
%"clarity of figures and general presentation. too much vs too little." (10pts)

%"referencing: relevant works cited accurately?" (5pts)
