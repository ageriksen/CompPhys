\documentclass[10pt, twocolumn]{revtex4-1}
\listfiles               %  print all files needed to compile this document

\usepackage{amsmath}
\usepackage{xparse}
\usepackage{graphicx}
\usepackage{dcolumn}
\usepackage{bm}
\usepackage[colorlinks=true,urlcolor=blue,citecolor=blue]{hyperref}
\usepackage{color}
\usepackage{physics}
\usepackage{algorithm2e}
\usepackage{algpseudocode}
\usepackage{pgfplots}
\usepackage{natbib}

\pgfplotsset{compat=1.15}

%\begin{figure}[hbtp]
%\includegraphics[scale=0.4]{.pdf}
%\caption{}
%\label{fig:}
%\end{figure}

%\begin{tikzpicture}
%    \begin{axis}[
%            title= Earth-Sun system, Forward Euler integration,
%            xlabel={$x$},
%            ylabel={$y$},
%        ]
%        \addplot table {../runresults/earthEuler2body.dat}
%    \end{axis}
%\end{tikzpicture}

\begin{document}
\title{%
    Project 4\\
    \large Studies of phase transition in magnetic systems}
\author{Anders Eriksen}
\begin{abstract}
    The motivation of the project, is to explore stochastic modeling of nature.
    A magnetic phase shift is explored with Metropolis Markov Chain Monte Carlo simulations. The system is simulated for various $2$ dimensional lattice
    sizes over a scaled temperature range. The system is modeled using the Ising method for a ferro magnet, with no assumed external magnetic field.
    Near the critical temperature, there is an indication of a discontinuity in correlation, but what is likely lacking data leaves a shaky conclusion.
\end{abstract}
\maketitle

\section{Introduction}
The aim here, is to get used to the Monte Carlo simulation of a system and see how it challenges the intuition of the user. %%%%%%%%%
%%%%%%%%%%retouch!!
With the Ising method to simulate the system, run a comparative test of energies and control these to a probabilistic rule which
allows for some dynamicism in the system. %%%%%%%%
%%%%%%%%%%%%%%%%%%% end retouch
As with most things, I started from the bottom with a 2 by 2 lattice and acode meant specifially for this. \cite{MortenIsingmodel}


\section{Methods and theory}

We want to study a 2 dimensional ferromagnetic system through the Ising model, specifically in phase transitions.
The system has an energy
\[ E = -J \sum_{<kl>}^N s_k \, s_l \]
In which the "$<kl>$" signifies summing over neighbouring spots in the lattice only. $s_k = \pm 1$, and N is the total number of spins in
the latice. J is a coupling constant and for a ferromagnetic system is $J > 0$.
Changing 1 spin state will cause a change in energy of:
\[ \Delta E = 2 Js_l^1 \sum_{<k>}^N s_k \].

the relevant variables here, assuming there is no exchange of particles with the surroundings, but that the system is in a thermal bath starts with
the partition function $Z$ from the Helmholtz free energy, which in turn is a scaling factor for the probability.
\begin{align*}
    P _ { i } ( \beta ) = \frac { 1 } { Z }e ^ { - \beta E _ { i } }
    Z = \sum _ { i = 1 } ^ { M } e ^ { - \beta E _ { i } }
\end{align*}
From the probabilities, we can derive the average energy, $\ev{E}$ as
\begin{align*}
    \langle E \rangle = \sum _ { i = 1 } ^ { M } E _ { i } P _ { i } ( \beta ) = \frac { 1 } { Z } \sum _ { i = 1 } ^ { M } E _ { i } e ^ { - \beta E _ { i } }
\end{align*}
and the mean magnetization $\ev{|M|}$ as
\begin{align*}
    \ev{|M|} = \sum_i^M \Pr{\beta}_i = \frac{1}{Z} \sum_i^M |M_i| e^{-\beta E_i }.
\end{align*}
as well as a connected set of variances
\begin{align*}
    \sigma _ { E } ^ { 2 } = \left\langle E ^ { 2 } \right\rangle - \langle E \rangle ^ { 2 } \\
\sigma_{M }^{ 2 } = \left\langle M^{ 2 } \right\rangle - \langle M \rangle^{ 2 }
\end{align*}
leading to 2 further variables, heat capacity, $C_V$,  and susceptibility, $\chi$
\begin{align*}
    C _ { V } = \frac { 1 } { k _ { B } T ^ { 2 } } \sigma_E
    \chi = \frac { 1 } { k _ { B } T } \sigma
\end{align*}
%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
%The numerical issues I focus on through the project, is periodic boundary conditions as well as the metropolis algorithm. % Look further into
%these and discuss here.
%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%
We will use the Metropolis sampling rule, whose algorithm compares a uniformly chosen stochastic number between 0 and 1 with the probability ratio
of the new state with the current state. Looking at the probability function, this ratio would ultimately become $e^{e_i - E_{i+1}}= e^{\Delta E }$.
Looking at the sum, we assume also, that each lattice point is connected to 4 others, at all times. This means we are working with periodic boundary
conditions. An ilustration of such could be a toroid structure. with $n$ elements in a direction, going to $n+1$ means returning to place number $1$.


Starting small with a $2\times 2$ lattice to find as well as the mean average magnetic moment henceforth "mean magnetism". Additional valuable
properties are the specific heat capacity, as well as succeptability as functions of T, with periodic boundary conditions.
\[
    \ev{E(T)}, \qq{} \abs{M(T)}, \qq{} C_V(T), \qq{} \chi(T)
\] % include DESCRIPTIONS OF HOW TO FIND MAGNETIZATION, HEAT CAPACITY AND SUCCEPTIBILITY!!!
In the 2 dimensional case, we can write out the variables as
\begin{align*}
    Z &= 2\qty( e^{-8\beta} + e^{8\beta} )
    &= 2\cdot 2\cosh{8\beta} \\
    \ev{E} &= \frac{1}{Z} 8\cdot \qty( 2(e^{-8\beta} - e^{8\beta}) )
    &= -8\tanh{8\beta} \\
    \ev{|M|} &= \frac{1}{Z} \qty( 8 e^{-8\beta} + 16 )
\end{align*}
The equations for $\ev{E^2}$ and it's magnetic equivalent is the same, exept for the number multiplied with the probability now is squared. The
variance are calculated as in the expression above, and can be found as\cite{Anna}
\[ \frac{\ev{E}}{L^2} = -1.99 \qq{} \frac{\ev{|M|}}{L^2} = 0.9886 \]
And with a similar relation to the variance
\[\frac{C_V}{L^2} = 0.032 \qq{} \frac{\chi}{L^2} = 3.993 \]
Where the exact values are found by setting $\beta=1$ and the severely restricted lattice size.

These values will form the basis of the benchmarking for numerical computations on the model. These benchmarks are found using a scaled temperature
$T=1 \frac{J}{k_B T}$, where here J is Joule and not the coupling constant J referred to in the rest of this project. the main purpose of this definition
is to scale the equations so that we avoid finicky floating point opperations and reduce numerical round off errors.
%%%% algorithm begin
\begin{algorithm}
    initialize a probability ratio array for all 4 posibilities of the\\
    switch in spinstate. \\
    \For{ the range of spin states }{
        1: Chose a random spinstate in the lattice\\
        2: check the energetic gain in changing a configuration.\\
        3: compare corresponding probability ratio to a stochastic number $ a \in {0.0, 1.0}$\\
        \If{ $a <= \Pr{\Delta E}$ }{
            apply change\\
            Update magnetism for lattice\\
            update energy level for lattice\\
            }
    }
    \caption{The algorithm for 1 MC cycle. }
\end{algorithm}
%%%% algorithm end

Having Benchmarked and controlled our program for a simple system, I up the lattice size $L\times L$ to $L=20$. To avoid wasting cpu cycles on usesless
info that will at best be thrown out, an estimation of the equilibration time of the system is made. The simplest method here, is to just plot the
various expectation values as functions of the number of MC cycles. And determining by eye when the system reaches the desired stability. Time is measured in
sweeps of MC cycles per lattice. An interesting question, is whether or not the equilibration time depends on the starting position. Whether this is
ordered so all spins point in the same direction or random configuration. These first tests will be run with the initial temperature $T=1$. We will also
investigate the temperature $T = 2.4$ and whether or not it is possible to estimate equilibration time. Explored as functions over time.
%%%%%%%%%%%%%%%
Additionally I want to study the probabilities for energies, $\Pr(E)$, in effect counting up the number of times the energy $E$ comes up in the computation.
We begin our counting after having reached equilibrium to ensure statistically significant readout. We want the energetic variance $\sigma_E^2$.
%discuss results!
%%%%%%%%%%%%%%%%%%%%5

Having set up the system, I can now study it's evolution with regards to temperature. There is a phase shift of the system on the crossing of
a certain critical temperature $T_C$. Below this, the energy is low enough, so that the bias in energetic preference freezes the system towards the energetic
minimum. This should result in growing clusters of spins, untill the system eventually inhabits the minimum energy state where all spins point in the same
direction. With temperatures greater than $T_C$, the energy present lessens the bias towards the energetically preferable state. This means that the clusters
of similar spins are smaller and more spread, with a more random distribution.

%%%%%%%%%%%%%%%%
Near $T_C$ I can characterize several properties of the system with a power law behaviour. In the Ising model, the mean magnetisation is given by
\[ \ev{M(T)} \sim \qty( T - t_C )^{\beta} \qq{with} \beta = \frac{1}{8} \]
Here, $\beta$ is called the "critical exponent". % what is this?!?
Similar expressions can be found for heat capacity and susceptibility:
\begin{align*}
    C_V(T) &\sim \qty| T_C - T |^{\alpha}, \qq{} \alpha = 0 \\
    \chi(T) &\sim \qty| T_C - T |^{\gamma}, \qq{} \gamma = \frac{7}{4}
\end{align*}
The 0 exponent stems from logarithmic divergence, where the value
arises from a rewrite into the Taylor series, where $\qty| T_C - T |^{\alpha} \simeq -\ln(\qty| T_C - T | ) + O(\alpha^2)$. This is an exponentially growing
"spike" around the critical temperature.

Another important quantity is correlation length, $\xi$. For temperatures $T \gg T_C$, the correlation between the spins should be on the order of the
distance between each lattice point. Aproaching the critical temperature from above gives an exponential
growth in the correlation length.
\[ \xi(T) \sim \qty| T_C - T |^{-\nu} \]
%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%
The $2^{nd}$ order order correction is characterised by a $\xi$ spanning the system. A finite lattice, therefore has a correlation length proportional to
the lattice size. Using so-called "finite size scaling relations" I can relate the behaviour of $\xi$ to the infinite span. With this, the critical
temperature scales as
\[ T _ { C } ( L ) - T _ { C } ( L = \infty ) = a L ^ { - 1 / \nu } \]
Where $a$ is some constant and $\nu$ is as defined for $\xi$ above. When I set $T = T_C$, the above equations go to:
\begin{align*}
    \text{ mean magnetisation: } \\
    \langle \mathcal { M } ( T ) \rangle &\sim \left( T - T _ { C } \right) ^ { \beta } \rightarrow L ^ { - \beta / \nu }\\
    \text{ Heat capacity: } \\
    C _ { V } ( T ) &\sim \left| T _ { C } - T \right| ^ { - \gamma } \rightarrow L ^ { \alpha / \nu }\\
    \text{ and succeptibility: } \\
    \chi ( T ) &\sim \left| T _ { C } - T \right| ^ { - \alpha } \rightarrow L ^ { \gamma / \nu }
\end{align*}
%%%%%%%%%%%%%%%%%%%
The final point of inquiry is near the critical temperature $T_C$, examining the dependence of T and L for the listed characteristics.
We also want to time the tests, to compare between parallelization of the code. and finally compare the numerical critical temperature from a Monte Carlo
simulation to the closed-form solution found by Onsanger in 1944: $k T _ { C } / J = 2 / \ln ( 1 + \sqrt { 2 } ) \approx 2.269$ \cite{PhysRev.65.117}.



\section{Results and discussion}

With the analytical results above, the first point of order is to make a minimal code that allows for benchmarking and later add complexity. Borrowing
heavily from the "Isingmodel.cpp"\cite{MortenIsingmodel}, and modifying to fit the specifications. Controlling it against the analytical values, showed a fit
near the

\begin{table}[h]
    \begin{tabular}{ |l|l|l| }
        \hline
          $T = 1.0$ & $t 2.66646s$\\
        \hline
          $\ev{ E } / (N^2)$ & $-1.99599$\\
          $\ev{|M|} / (N^2)$ & $0.998645$\\
          $C_v\cdot k_B / (N^2)$ & $-1.59358e+07$\\
          $\chi \cdot k_B / (N^2)$ & $-3.98916e+06$\\
          \hline
        $T = 2.4$ & $t=5.31488s$\\
        \hline
          $\ev{ E } / (N^2)$ & $-1.64245$\\
          $\ev{|M|} / (N^2)$ & $0.881098$\\
          $C_v\cdot k_B / (N^2)$ & $-1.87336e+06$\\
          $\chi \cdot k_B / (N^2)$ & $-1.29389e+06$\\
          \hline
    \end{tabular}
\end{table}

The Monte Carlo method is, by nature a stochastic representation, where I simulate the system as it evolves with time. Therefore, We have no guarantee that
the state is in it's most likely form. As our statistical models are based on an equilibrium assumption, they do not give accurate results unless I am in
a stable position. As a test for this, I run the now benchmarked program over a lattice of $L=20$ spin states in 2 directions and store the expectation
energy and mean magnetization $\langle E \rangle$ and $\langle |M| \rangle$.\cite{Project4git}
\begin{figure}[hbtp]
\includegraphics[scale=0.4]{../Graphics/ExpectationEnergyL20.pdf}
    \caption{Plot of $\langle E \rangle$ for a lattice of size $L=20$ for temperatures $T = \qty{ 1.0, 2.4 }$. We can see that there clearly is
        a difference in the convergence of the different temperatures, with the higher temperatures having a higher average energy. This
        is as I would expect. We can see, that both graphs seem to have settled towards a stable value somewhere in between $10^2$ and $10^3$
        cycles through the lattice. What is not obvious, is that the numbers displayed are only $\frac{1}{100}$ of the actual values, as I failed
        to specify an x-axis, yet plotted every 100th element. this brings the Equilibration time closer to $10^4$, which is what I've used for the
        remainder of the project.}
\label{fig:ExpectEL20}
\end{figure}
We can see that for the low temperature, the expectation energy lies at about $-2J$ per sping, $J$ is here the coupling constant between the spin, not
Joule. Looking back at the Ising model, I can see that this means more or less every spin points in the same direction. As I increase the temperature,
we notice that the resting energy is higher. This makes sense if I consider that there is more energy within the system which allows for some spins to be
in less energetically preferential positions.
\begin{figure}[hbtp]
    \includegraphics[scale=0.4]{../Graphics/ExpectationMagnetismL20Log.pdf}
    \caption{we can see that the magnetization approaches 1 for the lower temperature. as it is scaled in our model, this means that efectively all spins
    point in the same direction. as I increase the temperature, and the spins can change a bit more freely, I get a lower magnetization. there is increased
    turbulence for the higher temperature, but i would say I have reached a mostly stable state at around $10^2$ or slightly above, as with the energy.
    this is in agreement with fig \ref{fig:expectel20}.}
\label{fig:expectml20}
\end{figure}

furthermore, the rate of change as I evolve the system over time should stabilize as I reach equilibrium. To capture this, I recorded each accepted change
to the lattice, while I stored each cycle into an array. The accumulating sum was then scaled with the number of Monte Carlo cycles for each step and plotted,
see fig \ref{fig:Accepted}
\begin{figure}[hbtp]
    \includegraphics[scale=0.4]{../Graphics/AcceptedConfigurationsVsTime.pdf}
    \caption{Figure of the number of accepted configurations during my run. Noticeably, the lower temperature tends towards an equilibrium with greater
    numbers of accepted changes, while the higher temperature seems to settle down slightly with time. One should note the order of magnitude difference
    between the lower and higher temperature acceptance rates. A difference on the order of $10^3$ shows how much more active the system is with the
    additinal temperature.}
\label{fig:Accepted}
\end{figure}


Another interesting facet, is the probability of each energy for the system durign these states. As I measure statistical values, probability would merely
be a scaled frequency of energies. Storing these, I can make a normalized histogram to ilustrate, see fig\ref{fig:PrEhist}
\begin{figure}[hbtp]
    \includegraphics[scale=0.4]{../Graphics/energyHistogram.pdf}
    \caption{A scaled histogram of the occurences of various energies of the lattice over time. The upmost one is of a temperature $T=1.0$ and the lower
    has $T=2.4$. As one would expect, without energy in the system, there is very little the particles in the lattice can do to not follow the energetically
    advantageous configuration. We can also notice, that between the 2 largest columns, there is a gap of $8J$, which is the energy from 4 ordered to 1
    disordered spin state, which follows our model. There is another slight bump with $8J$ less energy as well. The lower of the 2 is for the more energetic
    $T=2.4$ state. Here I see a far greater spread of energies, this time there are fewer configurations where all spins point in the same direciton, but the
    vast majority of the states are in above the $-400$ energy state, which would be half of the low-energy state. The shape is somewhat reminiscent of the
    Boltzmann distribution of states.}
\label{fig:PrEhist}
\end{figure}
If I look at the histogram in figure \ref{fig:PrEhist}, I would place the peak probability in $799$ and $450$ or $475$ respectively, based on the height
difference observed. According to my computed variance, $\sigma_E^2=$, I can check the validity of our measurements.


Having observed these changes in the state over the different temperatures, I now want to study the system to see if there is a gradual change, or a more
distinct one, akin to the shift from ice to water with temperature. As my model was not object oriented, The changes required were somewhat extensive. The
result was a second, eventually third, iteration of my Monte Carlo simulation, "MCCycleLarge". With the setup, I attempted to remove as much as possible from
the various loops. The result was discarding the previously stored values in favour of an "ExpectationValues" array accumulating data through the sweeps. I
also split each set of cycles in 2 loops. The first was to equilibrise the system without storing any data. The split was motivated by a desire to avoid
if-tests. These are in a function which I call within a nested loop of the ranges of temperature and lattice size. Sweeping over lattices
$L = \qty{40, 60, 80, 100}$, and temperatures $T \in \qty{2.2, 2.3}$ with a step of $\Delta T = 0.01$, using a foreknowledge of Onsanger's results at
$T_C = 2.27$, to shrink the range, while keeping some precision. I did not quite have the time to parallellize the code, so I saw it as a necessary
sacrifice. After leaving the program to slow cook overnight, I could finally start to process the results.

\begin{figure}[hbtp]
    \includegraphics[scale=0.5]{../Graphics/VariablesVsTemperature.pdf}
    \caption{The figure above is the mean energy, $\ev{E}$, the mean magnetization, $\ev{|M|}$, the heat capacity a constant volume,
    $C_V$ scaled by $k_B\cdot T^2$ for simplicity during calculation, effectively the energetic variance per spin, and the susceptibility
    $\chi$ scaled by $k_B\cdot T$ to the effect of taking the variance of the absolute magnetization of the system. Following Onsanger's
    prediction, I should expect to see a critical temperature at around the temperature 2.27. The mean energy per particle seems to increase
    fairly linearly with temperature, but the magnetization drops of towards 0, in what seems to be an exponential trend, with the full decent
    beginning in between 2.26 and 2.28. I can also see the beginning of an extremum in the range 2.26 to 2.30 for the heat capacity of the system,
    seeming to suggest that this is the range where the greatest amount of energy is required to change the temperature. This too is to be expected
    in a phase shift There could possibly be a spike in the susceptibility in this range as well, but the different lattice sizes produce so widely
    differing results here, that I am loathe to give a definitive suggestion.}
\label{fig:VarVsTime}
\end{figure}

Ideally, following the idea of a phase shift, I should see some sort of extrema in this range. The $\ev{E}$ is mostly linear throughout the range,
and the susceptibility spreads out far too much for me to give any indications as to the magnetic change of state. For the latter 2, there is some change,
however. The range around $2.27$ seems to be the temperatures at which the mean magnetization begins to plummet, indicating a far less cohesive spin direction
after this rough value, where there would likely be little coherence in spin direction across the lattice. The heat capacity too, has a peak in this rough
area.

Looking at the graphs, there seems to be a top around 2.28 and 2.3, with regards to the heat capacity $C_V$. Equation number 3, \cite{Project4}, in the
project description gives a neat linear depence between the critical temperature for a given lattice size at a sett exponent $\nu = 1$, as:
\[ T_C( L ) = T_C ( L = \inf ) + aL^{-1} \]
Comparing the maximal values for the heat capacity, we can get a measure of the seeming linearity here. A linear fit, gives the critical temperature
at $L = \inf$ as $\approx 2.304$.
\begin{figure}[hbtp]
    \includegraphics[scale=0.4]{../Graphics/LinearRegressionCV.pdf}
    \caption{Linear regression fit of the maximal values of $C_v$ found in the range $2.1$ to $2.3$, Why the graph is displaced to such a degree is
    uncertain, but likely has to do with inacuracies in provided data proving difficult to make a fit of.}
\label{fig:expectml20}
\end{figure}

Another way to approximate, is to take the mean and standard error of the critical temperatures for the Heat capacity and susceptibility, and taking the mean
over different lattice sizes. Yielding the results:
\begin{table}[h]
    \begin{tabular}{ |l|l|l| }
    \hline
        $T_{c,C_v}$ & $2.287 \pm 0.004$ \\
        $T_{c,\chi}$ & $2.29 \pm  0.007$ \\
    \end{tabular}
\end{table}



\section{conclusion}

There seems to be indications of a phase shift in the area of $2.27, 2.30$, as I can see the system behaviour differing over the temperatures, but the "peak"
in heat capacity is not very pronounced, and is not a reliable proof here. If there was indeed a phase shift, then I would expect to see a fairly high
difference in the energies of some particles with regards to others. I take ice melting as an example here. During the process of melting, som molecules
would be frozen while others would be free to move about. After having melted, all particles are equally as free to move. Similarly, if before the phase
shift, the molecules were kept in place by the energy needed to supplant the energetically preferable configuration, then around the area where they could
"break free", I would expect to see a more sporadic shift in areas, leading to a far greater spred from the mean.

We can also see that after reaching a temperature of $2.4$, the rate of change is orders of magnitude above the lower temperature, suggesting a far more
dynamic system at these later stages. Furthermore, the linear fit of the heat capacity maxima gave an intercept of $2.304$, which means a relative error to
Onsanger's result of $\frac{(2.304 - 2.269)}{ 2.269 } = 0.015$.

This should lead to quite a spike in the heat capacity, which I
simply don't see. I expect this fact comes from a lack of data. The stochastic nature of the Monte Carlo methods demand a great deal of points. Points which I
was unable to provide. If I had been able to scrounge up the time to parallellize the code I believe I could have reproduced a far stronger peak, as well less
drift between the lattice sizes.

While the code gave the correct energies for given configurations of the lattice, as well as converged towards the correct analytical values for the closed
form 2 by 2 solution, If I initialized the lattice in a random position, the resulting convergence was towards a number more negative than $-2J$ per particle,
something is unphysical. I do not know if this is a fault in the code, the model or my implementation of it. It is, nonetheless, important to bring up, should
a problem arise.

Another point of research which could be usefull, is the state where all spins are flipped. In this instance, the energy wouldn't change, and thus it should
posess no suppression from the model, and yet I believe this is a very unlikely event given the decoupling of the spins with their further neighbours. I do
not know much about it, but I believe that for a system with no external force a so called "wolf cluster" \cite{WolfCluster}.

The project has some glaring flaws, in that it is neither object oriented, nor is it parallellized. The object orientation would have helped in both making
adjusting the code easy, as well as making the switching between tasks easier. for instance, when going from benchmarking and establishing a general
behaviour of the system, to measuring probabilities and eventually to running a larger scale simulation over multiple variables, I was eventually forced
to simply copy the program and modify it, rather than potentially losing methods to reproduce earlier results should an error occur. With a system in place
to catch, e.g. differing variables to store, I could perhaps tweak the various classes while keeping the overal structure unchanged.

Not having a parallellized code also proved difficult in that even leaving the computation runing over a near 10 hour period, the results were rather poor,
with no particular spikes in any variables. Comparing with other run results known to reach MC cycles of up to near $10^9$, it is quite understanding that
my measly $10^4$ per temperature and lattice size can hardly compare.


\bibliography{\string~/Documents/bibliography/Bibliography}
\end{document}
